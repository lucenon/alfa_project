# Сервис для классификации тональности текста (Fast API)

Тестовое задание в рамках отбора на стажировку в Альфа-Банк. 

Сервис обслуживает модель логистической регрессии для классификации тональности текста. Модель обучена на данных, взятых с сайта Kaggle ([ссылка на датасет](https://www.kaggle.com/datasets/mar1mba/russian-sentiment-dataset)). Датасет содержит предложения на русском языке, источник данных и класс тональности (0 - нейтральный, 1 - позитивный, 2 - негативный). 

Обучение модели продемонстрировано в Model.ipynb.

## Минимальные требования
- Python 3.8+
- Установленные зависимости

## Описание проекта
### Схема проекта
```plaintext
alpha_project/
├── app/                 
│   ├── config.py
│   ├── logger.py
│   ├── model_service.py
│   ├── schemas.py
│   └── utils.py     
├── model/
│   └── pipeline.joblib
├── Dockerfile  
├── main.py 
├── Model.ipynb               
├── README.md              
└── requirements.txt
```

### Модули
- __main.py__ - содержит эндпоинт для получения результата работы модели
- __logger.py__ - консольный логгер для вывода информации о работе приложения
- __config.py__ - конфигурационный файл, содержит пути к файлам pipeline
- __model_service.py__ - код загрузки и инференса модели
- __schemas.py__ - классы Pydantic для контроля входных и выходных данных сервиса
- __utils.py__ - вспомогательные функции (подготовка данных и валидация)

### Принцип работы
Функция `load_artifacts`, объявленная в модуле __model_service.py__, загружает пайплайн (векторизацию и модель) из предварительно полученного файла __pipeline.joblib__ один раз при запуске сервера. 

Обращение к модели осуществляется с помощью функции `predict`. Сервис принимает POST-запрос с помощью эндпоинта `predict_route`. Входные и выходные данные прописаны в схеме Pydantic, чтобы обеспечить корректность вывода.

После получения сервером и перед подачей в модель для предсказания, данные предварительно очищаются с помощью функции `preprocess`, объявленной в __utils.py__. 

Текстовые данные проходят векторизацию методом `TF-IDF`, который учитывает важность слов в корпусе. Эта векторизация выполняется с помощью предварительно обученного пайплайна.

Затем с использованием того же пайплайна получается предсказание. В ответ на запрос в функционале API возвращается метка класса, название класса (neutral, positive и negative) и флаг, обозначающий, было ли предсказание получено с помощью модели или без неё. Если данные нельзя классифицировать корректно, например, это цифры, символы или пустая строка, то по умолчанию возвращается класс 0 (neutral), а модель не используется. Результат возвращается в формате json.

Для удобства запуска сервиса был добавлен Dockerfile, также можно скачать Docker образ и запустить его.

## Способы запуска
### Запуск без Docker
1. Скачать репозиторий
```bash
git clone https://github.com/lucenon/alfa_project.git
```
2. Установить зависимости
```bash
pip install -r requirements.txt
```
3. Запустить сервер
```bash
uvicorn main:app --host 0.0.0.0 --port 8000
```
### Запуск с Docker
#### Запуск готового образа 
Выполнить команды
```bash
docker pull lucenon/alfa_project
docker run -p 8000:8000 lucenon/alfa_project
```
#### Сборка и запуск вручную
Выполнить команды
```bash
docker build -t alfa_project .
docker run -p 8000:8000 alfa_project
```
## Примеры использования API
### С помощью curl
Тело запроса должно содержать поле "text".

Bash:
```bash
curl -X POST "http://localhost:8000/predict" -H "Content-Type: application/json" -d '{"text": "Сегодня отличный день"}'
```
PowerShell:
```commandline
curl.exe -X POST "http://localhost:8000/predict"   -H "Content-Type: application/json"   -d '{\"text\": \"Сегодня отличный день\"}'
```
CMD:
```commandline
curl -X POST http://localhost:8000/predict -H "Content-Type: application/json" -d "{\"text\": \"Сегодня отличный день\"}"
```
Альтернативный способ для некоторых терминалов или для более длинных запросов:
1. Создать файл data.json c содержимым:
```commandline
{"text": "Сегодня отличный день"}
```
2. Выполнить запрос
```bash
curl -X POST "http://localhost:8000/predict" -H "Content-Type: application/json" -d @data.json
```
### С помощью браузера
1. Запустить приложение
2. Открыть `http://localhost:8000/docs`
3. В поле ввода `predict` вставить нужный текст и выполнить. Пример:
```bach
{
    "text": "Сегодня отличный день"
}
```
Пример ответа:
```bach
{
  "class_": "positive",
  "label": 1,
  "model_bypassed": false
}
```
